<!DOCTYPE html>



  


<html class="theme-next pisces use-motion" lang="">
<head><meta name="generator" content="Hexo 3.8.0">
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Transformer,">










<meta name="description" content="æœ¬æ–‡å…¶å®å†™çš„æœ‰äº›è¿Ÿåˆ°ï¼Œæ¯•ç«Ÿè¿™æ˜¯è°·æ­Œ17å¹´6æœˆçš„å·¥ä½œï¼Œä¸è¿‡å¥½æˆä¸æ€•æ™šï¼Œè¿™é¡¹å·¥ä½œäº®ç‚¹åœ¨äºä¸ç”¨CNN,RNNä¹Ÿèƒ½å¾—åˆ°STOAçš„æ•ˆæœ, è€Œç†è®ºä¸Šçš„æŒ‡å¯¼æ„ä¹‰åœ¨äº  Self-Attentionæ€æƒ³ Transformer ç»“æ„  è¿™é‡Œæ¨¡å‹ç»“æ„å¼ºæ¨å¦ä¸€ä¸ªåšå®¢ï¼Œè®²çš„ååˆ†æ¸…æ¥šï¼ŒæŒ‰ç…§æ•°æ®çš„å¤„ç†æµç¨‹æ¥è®²ï¼Œååˆ†æ¸…æ¥šã€‚Transformerå…¶å®Transformer è¿˜æ˜¯ä¸€ä¸ªSeq2Seq çš„ç»“æ„ï¼Œä½†æ˜¯Transform">
<meta name="keywords" content="Transformer">
<meta property="og:type" content="article">
<meta property="og:title" content="Transformer">
<meta property="og:url" content="http://yoursite.com/2018/11/02/Transformer/index.html">
<meta property="og:site_name" content="CSNLPå­¦å¾’">
<meta property="og:description" content="æœ¬æ–‡å…¶å®å†™çš„æœ‰äº›è¿Ÿåˆ°ï¼Œæ¯•ç«Ÿè¿™æ˜¯è°·æ­Œ17å¹´6æœˆçš„å·¥ä½œï¼Œä¸è¿‡å¥½æˆä¸æ€•æ™šï¼Œè¿™é¡¹å·¥ä½œäº®ç‚¹åœ¨äºä¸ç”¨CNN,RNNä¹Ÿèƒ½å¾—åˆ°STOAçš„æ•ˆæœ, è€Œç†è®ºä¸Šçš„æŒ‡å¯¼æ„ä¹‰åœ¨äº  Self-Attentionæ€æƒ³ Transformer ç»“æ„  è¿™é‡Œæ¨¡å‹ç»“æ„å¼ºæ¨å¦ä¸€ä¸ªåšå®¢ï¼Œè®²çš„ååˆ†æ¸…æ¥šï¼ŒæŒ‰ç…§æ•°æ®çš„å¤„ç†æµç¨‹æ¥è®²ï¼Œååˆ†æ¸…æ¥šã€‚Transformerå…¶å®Transformer è¿˜æ˜¯ä¸€ä¸ªSeq2Seq çš„ç»“æ„ï¼Œä½†æ˜¯Transform">
<meta property="og:locale" content="default">
<meta property="og:image" content="http://yoursite.com/2018/11/02/Transformer/transformer_encoder_selfattention.jpg">
<meta property="og:image" content="http://yoursite.com/2018/11/02/Transformer/transformer_position_embedding.jpg">
<meta property="og:image" content="http://yoursite.com/2018/11/02/Transformer/transformer_encoder.jpg">
<meta property="og:image" content="http://yoursite.com/2018/11/02/Transformer/transformer_structure.jpg">
<meta property="og:updated_time" content="2018-11-05T08:23:39.593Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Transformer">
<meta name="twitter:description" content="æœ¬æ–‡å…¶å®å†™çš„æœ‰äº›è¿Ÿåˆ°ï¼Œæ¯•ç«Ÿè¿™æ˜¯è°·æ­Œ17å¹´6æœˆçš„å·¥ä½œï¼Œä¸è¿‡å¥½æˆä¸æ€•æ™šï¼Œè¿™é¡¹å·¥ä½œäº®ç‚¹åœ¨äºä¸ç”¨CNN,RNNä¹Ÿèƒ½å¾—åˆ°STOAçš„æ•ˆæœ, è€Œç†è®ºä¸Šçš„æŒ‡å¯¼æ„ä¹‰åœ¨äº  Self-Attentionæ€æƒ³ Transformer ç»“æ„  è¿™é‡Œæ¨¡å‹ç»“æ„å¼ºæ¨å¦ä¸€ä¸ªåšå®¢ï¼Œè®²çš„ååˆ†æ¸…æ¥šï¼ŒæŒ‰ç…§æ•°æ®çš„å¤„ç†æµç¨‹æ¥è®²ï¼Œååˆ†æ¸…æ¥šã€‚Transformerå…¶å®Transformer è¿˜æ˜¯ä¸€ä¸ªSeq2Seq çš„ç»“æ„ï¼Œä½†æ˜¯Transform">
<meta name="twitter:image" content="http://yoursite.com/2018/11/02/Transformer/transformer_encoder_selfattention.jpg">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2018/11/02/Transformer/">





  <title>Transformer | CSNLPå­¦å¾’</title><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  








</head>

<body itemscope="" itemtype="http://schema.org/WebPage" lang="default">

  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope="" itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">CSNLPå­¦å¾’</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br>
            
            About
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            Archives
          </a>
        </li>
      
        
        <li class="menu-item menu-item-github">
          <a href="https://github.com/csnlp" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-question-circle"></i> <br>
            
            github
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/11/02/Transformer/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="CSNLP Apprentice">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="CSNLPå­¦å¾’">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">Transformer</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-11-02T10:35:36+08:00">
                2018-11-02
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/NLP/" itemprop="url" rel="index">
                    <span itemprop="name">NLP</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>æœ¬æ–‡å…¶å®å†™çš„æœ‰äº›è¿Ÿåˆ°ï¼Œæ¯•ç«Ÿè¿™æ˜¯è°·æ­Œ17å¹´6æœˆçš„å·¥ä½œï¼Œä¸è¿‡å¥½æˆä¸æ€•æ™šï¼Œè¿™é¡¹å·¥ä½œäº®ç‚¹åœ¨äºä¸ç”¨CNN,RNNä¹Ÿèƒ½å¾—åˆ°STOAçš„æ•ˆæœ, è€Œç†è®ºä¸Šçš„æŒ‡å¯¼æ„ä¹‰åœ¨äº</p>
<ul>
<li>Self-Attentionæ€æƒ³</li>
<li>Transformer ç»“æ„</li>
</ul>
<p>è¿™é‡Œæ¨¡å‹ç»“æ„å¼ºæ¨å¦ä¸€ä¸ªåšå®¢ï¼Œè®²çš„ååˆ†æ¸…æ¥šï¼ŒæŒ‰ç…§æ•°æ®çš„å¤„ç†æµç¨‹æ¥è®²ï¼Œååˆ†æ¸…æ¥šã€‚<br><a href="https://nlppupil.github.io/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/2018/06/09/Attention-is-all-you-need-%E8%A7%A3%E8%AF%BB.html" title="Transformer" target="_blank" rel="noopener">Transformer</a><br>å…¶å®Transformer è¿˜æ˜¯ä¸€ä¸ªSeq2Seq çš„ç»“æ„ï¼Œä½†æ˜¯Transformer å´æ‰“ç ´äº†ä¸€ç§è§‚ç‚¹ï¼ŒSeq2Seq ä¸€å®šæ˜¯åŸºäºRNNï¼ŒLSTM æ¥è¿›è¡Œçš„ã€‚</p>
<h2 id="Encoder-éƒ¨åˆ†"><a href="#Encoder-éƒ¨åˆ†" class="headerlink" title="Encoder éƒ¨åˆ†"></a>Encoder éƒ¨åˆ†</h2><p>Encoderçš„ç»„ä»¶</p>
<ul>
<li>Multi-Head Attention ç»„ä»¶</li>
<li>Feed-Forward ç»„ä»¶</li>
</ul>
<p>æˆ‘è¿™é‡Œç”¨ç»„ä»¶ï¼Œæ˜¯å› ä¸ºæ¯ä¸€ä¸ªMulti-Head Attention &amp; Feed-Forward æ“ä½œä¹‹åéƒ½ä¼šç´§è·Ÿ</p>
<ul>
<li>residual connection</li>
<li>layer normalization<br>è¿™é‡Œå¯¹è¿™äº›æ“ä½œæ”¾åœ¨ä»‹ç»å®ŒMulti-Head Attention å’Œ Feed-Forwardä¹‹åè°ˆ</li>
</ul>
<h3 id="Multi-Head-Attentionç»„ä»¶"><a href="#Multi-Head-Attentionç»„ä»¶" class="headerlink" title="Multi-Head Attentionç»„ä»¶"></a>Multi-Head Attentionç»„ä»¶</h3><p><img src="transformer_encoder_selfattention.jpg" alt=""><br>åæ˜ åˆ°å…¬å¼ä¸Š<br>$$\text{MultiHead}(Q, K, V) = \text{Concat}(head_1, \dots, head_h)W^{O}$$<br>where   $$\text{head}_i = \text{Attention}(QW_i^Q, KW_i^K, VW_i^V)$$   $$\text{Attention}(Q, K, V) = \text{softmax}(\frac{QK^T}{\sqrt{d_v}})V$$<br>å…¶ä¸­ å¯¹äºSelf-Attentionæ¥è®²$K = Q = K \in R^{d_{model}}$ ,$W_i^Q \in R^{d_{model} \times d_k}$, $W_i^K \in R^{d_{model} \times d_k}$, $W_i^V \in R^{d_{model} \times d_V}$</p>
<p>è¿™ä¹ˆåšçš„Motivationæ˜¯ä»€ä¹ˆ<br><blockquote><p>Instead of performing a single attention fuction with $d_{model}$ dimensional keys, values and queries, we found it benefical to linearly project the queries, keys and values h times with different learned linear projects to $d_k, d_k$ and $d_v$ dimensions respectively. </p>
</blockquote></p>
<h3 id="Feed-Forwardç»„ä»¶"><a href="#Feed-Forwardç»„ä»¶" class="headerlink" title="Feed-Forwardç»„ä»¶"></a>Feed-Forwardç»„ä»¶</h3><p>æ¯ä¸€ä¸ªMulti-Head Attentionä¹‹åéƒ½ä¼šç´§è·ŸFeed-Forwardç»„ä»¶, Feed-Forward ç›¸å¯¹ç®€å•,åªæœ‰ä¸¤å±‚ï¼Œç¬¬ä¸€å±‚ååŠ äº†ä¸€ä¸ªReLU. ç”¨å…¬å¼è¡¨ç¤º:  $$FFN(x) = max(0, xW_1 + b_1) W_2 + b_2$$ å…¶ä¸­ $x \in R^{lenght \times d_{model}}, W_1 \in R^{d_{model} \times d_m}, W_2 \in R^{d_m \times d_{model}}$</p>
<h3 id="Residual-Connection-amp-Layer-Normalization"><a href="#Residual-Connection-amp-Layer-Normalization" class="headerlink" title="Residual Connection &amp; Layer Normalization"></a>Residual Connection &amp; Layer Normalization</h3><p>åº–ä¸è§£ç‰›è¿™é‡Œè®²æ¸…æ¥šè¿™ä¸¤ä¸ªæ“ä½œ</p>
<ul>
<li>Residual Connection<br>æ˜¯é’ˆå¯¹ä¸€ä¸ªç½‘ç»œå‡½æ•°æ¥è®²ï¼Œæˆ‘ä»¬å‡å®šè¿™ä¸ªç½‘ç»œçš„è¾“å…¥ä¸ºx,è¾“å‡ºä¸ºLayer(x), é‚£ä¹ˆResidual Connectionå¯¹äºè¿™ä¸ªLayerçš„æ“ä½œå°±æ˜¯$$Residual(x) = x + Layer(x)$$ï¼Œ æ®‹å·®ç½‘ç»œæ˜¯ä¸ºäº†è®©æ·±å±‚ç½‘ç»œæ¢¯åº¦æ›´æ˜“ä¼ æ’­ï¼Œå¯ä»¥ç†è§£ä¸ºä¸ºäº†è®­ç»ƒæ–¹ä¾¿é‡‡å–çš„ç­–ç•¥(è¿™é‡Œæˆ‘çš„ç†è§£ä¸ä¸€å®šæ·±å…¥ï¼Œå¸Œæœ›åŒé“èƒ½æŒ‡å‡º)</li>
<li>Layer Normalization<br>è¿™ä¸ªä¹Ÿæ˜¯ä¸ºäº†è®©è®­ç»ƒç¨³å®šé‡‡å–çš„ç­–ç•¥ï¼Œè¿™é‡ŒNormalizationçš„ç­–ç•¥å¾ˆå¤šBatch Normalization, Layer Normalizationç­‰,è½å®åˆ°ä»£ç ä¸Šå¯èƒ½å°±æ˜¯ä¸€ä¸ªè°ƒç”¨åº“çš„æ“ä½œ $LayerNorm(x)$ æœ€åç»è¿‡Residual Connectionå’Œ Layer Normalizationå¾—åˆ°çš„æ“ä½œå°±æ˜¯<br>$$\text{LayerNorm}(x + SubLayer(x))$$</li>
</ul>
<p>ä¸€ä¸ªMulth-Head Attentionç»„ä»¶ å’Œ ä¸€ä¸ªFeed-Forwardç»„ä»¶ ç»„æˆä¸€ä¸ªLayer, è€Œå¤šä¸ªLayer ç»„æˆäº†Encoderã€‚(Encoder is composed of a stack of N=6 identical layers)<br>åœ¨è¿™é‡Œæˆ‘ä»¬æ‹ä¸€ä¸‹è¾“å…¥å’Œè¾“å‡º: å¯¹äºLayer çš„è¾“å…¥å…¶ç»´åº¦ä¸º $R^{\text{length} \times {d_{model}}}$, è€Œç»è¿‡ (Multi-Head Attention, Feed-Forward) ä»ç„¶æ˜¯$R^{\text{length} \times {d_{model}}}$ã€‚</p>
<h3 id="å…³äºPosition-Embedding"><a href="#å…³äºPosition-Embedding" class="headerlink" title="å…³äºPosition Embedding"></a>å…³äºPosition Embedding</h3><p><em>Attention Is All You Need</em> çš„å¾ˆå¤§çš„äº®ç‚¹åœ¨äºæ²¡ç”¨RNNçš„ç»“æ„ï¼Œä½†æ˜¯å¯¹äºè¯­è¨€è¿™æ ·çš„åºåˆ—æ•°æ®ï¼ŒPositionä¿¡æ¯è¿˜æ˜¯å¾ˆé‡è¦çš„ï¼Œä¸ºæ­¤éœ€è¦äººä¸ºçš„å¼•å…¥Position Embeddingä¿¡æ¯ï¼ŒåŸæ–‡ç›´æ¥å°±ç»™äº†å…¬å¼ï¼Œæˆ‘è¯´ä¸ä¸Šæ¥è¿™æ˜¯æ€ä¹ˆå¾—åˆ°,è¿™é‡Œä»…ä»…è®°å½•ä¸€ä¸‹æœ‰è¿™ä¸ªPosition Embedding <img src="transformer_position_embedding.jpg" alt=""> </p>
<p>åŸºæœ¬ä¸Šåˆ°è¿™é‡Œï¼Œå¯¹Encoderçš„ç»“æ„åº”è¯¥å¾ˆç†Ÿæ‚‰ï¼Œå‚è§ä¸‹å›¾<img src="transformer_encoder.jpg" alt="" title="Transformer Encoderç»“æ„"> æˆ‘è¿™é‡Œæœ€åä»ä¸‹åˆ°ä¸Šæ‹ä¸€é: Inputè¿›æ¥ï¼Œå…ˆè¿›è¡Œè¯åµŒå…¥(Input Embedding), ç„¶ååŠ å…¥ä½ç½®ä¿¡æ¯(Position Embedding), è€Œåè¿›å…¥Self-Attentionæ¨¡å—(Multi-Head Attention), æ³¨æ„å›¾ä¸­çš„<em>Add &amp; Norm</em> å…¶å®ä¹Ÿå°±æ˜¯æŒ‡çš„<strong>Residual &amp; Layer Normalization</strong>. å®Œæˆäº†Self Attention ä¹‹åè®°ä½æ­¤æ—¶è¾“å‡ºä»ç„¶å’ŒåŸæ¥è¾“å…¥ç»´åº¦æ˜¯ä¸€æ ·çš„ä»ç„¶æ˜¯$R^{d_{model}}$ã€‚ æ¥ä¸‹æ¥å°±æ˜¯Feed-Forward ç»„ä»¶ï¼ŒåŒæ ·çš„ Add &amp; Normalizationä¸€æ ·å°±æ˜¯ <strong>Residual &amp; Layer Normalization</strong>ã€‚è¿™æ—¶å€™è¾“å‡ºä»ç„¶æ˜¯ä¸è¾“å…¥ç»´åº¦æ˜¯ä¸€æ ·çš„ã€‚å¦‚æœæŠŠä¸Šè¿°æ‰€æœ‰æ“ä½œçœ‹æˆä¸€ä¸ªBig Layer, è¿™äº›Big Layer å åŠ å¤šæ¬¡(è°·æ­Œè®ºæ–‡æ˜¯å åŠ äº†6æ¬¡ï¼Œå°±å¾—åˆ°äº†Encoderç»“æ„)</p>
<h2 id="Decoderçš„ç»“æ„"><a href="#Decoderçš„ç»“æ„" class="headerlink" title="Decoderçš„ç»“æ„"></a>Decoderçš„ç»“æ„</h2><p>æœ‰äº†å‰é¢Encoderçš„è®²è§£ï¼Œåç»­ç›¸å¯¹ç®€å•,ä¸ºäº†ä¾¿äºç†è§£æˆ‘è´´ä¸€å¼ Transformerçš„æ•´ä½“ç»“æ„å›¾<img src="transformer_structure.jpg" alt="" title="Transformer Structure"> å…ˆæ˜¯Self-Attentionï¼Œ ç„¶åæ˜¯Encoder-Decoder Attention(å…¶å®ä¹Ÿå°±æ˜¯ä¼ ç»Ÿçš„Seq2Seqä¸­çš„Attention æœºåˆ¶ï¼Œå¯ä»¥å‚è€ƒæˆ‘ä¹‹å‰çš„åšæ–‡<a href="https://csnlp.github.io/2018/11/03/Attention/" title="Attentionæœºåˆ¶" target="_blank" rel="noopener">Attentionæœºåˆ¶</a><br>æˆ‘ä»¬ä¸å¦¨ğŸ¤”ä¸€ä¸‹ï¼šè¿™ä¸ªæµç¨‹æ˜¯æ€æ ·çš„ï¼Œé‚£æœºå™¨ç¿»è¯‘ä¸¾ä¾‹â€I like eating applesâ€, ç¿»è¯‘â€œæˆ‘ å–œæ¬¢ åƒ è‹¹æœâ€ï¼Œé—®é¢˜æ¥äº†åœ¨Encoderä¸­ï¼Œ â€œlikeâ€ æ³¨æ„åˆ° (attends to)â€Iâ€ â€œeatingâ€ å›ºç„¶æ²¡æœ‰é—®é¢˜,æ¯•ç«Ÿè¾“å…¥è¯­æ–™éƒ½ä¸€ä¸‹å­ç»™åˆ°Encoder, like åŒæ—¶æ³¨æ„åˆ°ä¸Šæ–‡çš„ â€œIâ€ å’Œ ä¸‹æ–‡çš„â€œeatingâ€, â€œapplesâ€ è¿™æ˜¾ç„¶æ˜¯å¥½äº‹ï¼Œè¿™æ ·Attendså¾—åˆ°çš„like æ˜¾ç„¶æ›´åŠ æœ‰é‡ç‚¹ã€‚ ç„¶è€Œï¼Œå¯¹äºdecoder æ¥è®²ï¼Œå¦‚æœä» start è¦ç¿»è¯‘å¾—åˆ°â€œæˆ‘â€ï¼Œè€ŒåŒæ—¶æ³¨æ„åˆ°æ¥ä¸‹æ¥æ˜¯â€æˆ‘â€ â€œå–œæ¬¢â€ â€œåƒâ€ â€œè‹¹æœâ€, é‚£ä¹ˆç¿»è¯‘â€œæˆ‘â€æ—¶ï¼Œç›´æ¥ä»ä¸‹ä¸€ä¸ªåºåˆ—æ‹¿ä¸‹æ¥ç¬¬ä¸€ä¸ªâ€œæˆ‘â€ å³å¯ï¼ŒåŒç†ï¼Œç¿»è¯‘â€œå–œæ¬¢â€æ—¶å€™(æ³¨æ„è¿™æ—¶å€™æ˜¯decoderè¾“å‡ºäº†â€œæˆ‘â€)ï¼Œæ³¨æ„åˆ°æ¥ä¸‹æ¥æ˜¯â€å–œæ¬¢â€ï¼Œé‚£ä¹ˆç›´æ¥copy å°±è¡Œäº†ï¼Œæ ¹æœ¬å°±ä¸éœ€è¦è®­ç»ƒäº†ã€‚çœ‹èµ·æ¥è²Œä¼¼è¯´çš„é€šï¼Œä½†æ˜¯è®­ç»ƒçš„æ¨¡å‹æ˜¯ä¸ºäº†è§£å†³ä»»åŠ¡ï¼Œå½“è®­ç»ƒå®Œæˆåï¼Œç»™äº†ä¸€ä¸ªsource è¯­å¥ï¼Œæ­¤æ—¶æ²¡æœ‰target è¯­å¥ï¼Œæ˜¾ç„¶è¿™æ—¶å€™æ¨¡å‹å°±æ²¡æœ‰åŠæ³•äº†ã€‚å› æ­¤ï¼Œæœ‰ä»¥ä¸‹æ³¨æ„ç‚¹ &lt;%centerquote%&gt; decoderçš„Self-Attentionç»„ä»¶ä¸encoderä¸­çš„ä¸åŒï¼Œdecoderä¸­çš„Self-Attentionåªèƒ½æ³¨æ„åˆ°(attends) å½“å‰output ä¹‹å‰çš„ä½ç½®çš„outputä¿¡æ¯&lt;%centerquote%&gt;  ä¹Ÿå°±æ˜¯è­¬å¦‚â€œæˆ‘â€ â€œå–œæ¬¢â€ï¼Œæ¥ä¸‹æ¥ç¿»è¯‘â€œåƒâ€ï¼Œè¾“å…¥æ˜¯â€œå–œæ¬¢â€ &amp; â€œæˆ‘â€çš„Self-Attentionã€‚  </p>
<p>é™¤æ­¤ä¹‹å¤–,Decoderå…¶å®æœ‰ä¸¤ç§Attention</p>
<ul>
<li>Self-Attention</li>
<li>Encoder-Decoder Attention</li>
</ul>
<p>å¯ä»¥ç€é‡ç†è§£ä¸€ä¸‹ï¼Œè‡³äºK, V, Q çš„å…·ä½“å«ä¹‰ï¼Œå¯ä»¥å‚è€ƒæˆ‘ä¹‹å‰çš„åšæ–‡<a href="https://csnlp.github.io/2018/11/03/Attention/" title="Attentionæ³›åŒ–" target="_blank" rel="noopener">Attentionçš„æ³›åŒ–</a></p>
<h2 id="Loss-Function"><a href="#Loss-Function" class="headerlink" title="Loss Function"></a>Loss Function</h2><p>å¯¹äºä¸¤ä¸ªæ¦‚ç‡åˆ†å¸ƒçš„Loss Functionï¼Œ æ—¢å¯ä»¥ç”¨Cross-Entropy ä¹Ÿå¯ä»¥ç”¨ Kullback-Leibler Divergenceã€‚å¯¹äºæ¦‚ç‡åˆ†å¸ƒpå’Œæ¦‚ç‡åˆ†å¸ƒqè€Œè¨€ï¼Œä»–ä»¬çš„Cross-Entropyå¯ä»¥å®šä¹‰ä¸º $$CE_p(q) = -E[ q(x) \log(p(x))]$$</p>
<h2 id="å¯¹ç°æœ‰å·¥ä½œçš„å¯å‘"><a href="#å¯¹ç°æœ‰å·¥ä½œçš„å¯å‘" class="headerlink" title="å¯¹ç°æœ‰å·¥ä½œçš„å¯å‘"></a>å¯¹ç°æœ‰å·¥ä½œçš„å¯å‘</h2><p>ç°åœ¨Transformer å·²ç»ä½œä¸ºTensorflowçš„ä¸€ä¸ªæ¨¡å—ä¸Šçº¿äº† <a href="https://github.com/tensorflow/tensor2tensor" title="Tensor2Tensor" target="_blank" rel="noopener">Tensor2Tensor</a>ã€‚è€ŒAttentionä¹Ÿçº¢ç«äº†ä¸€æ®µæ—¶é—´ï¼Œå°¤å…¶æ˜¯æå‡ºçš„Self-Attentionæ€æƒ³ï¼Œå¯èƒ½æ˜¯ç›¸æ¯”äºæ¨¡å‹ç»“æ„æ›´åŠ èƒ½å¼•äººæ€è€ƒä¹‹å¤„ã€‚</p>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/Transformer/" rel="tag"># Transformer</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2018/11/01/Attention/" rel="next" title="Attentionæœºåˆ¶">
                <i class="fa fa-chevron-left"></i> Attentionæœºåˆ¶
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2018/11/04/BERT/" rel="prev" title="BERTçš„å‘å±•å†ç¨‹">
                BERTçš„å‘å±•å†ç¨‹ <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">CSNLP Apprentice</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">6</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">1</span>
                  <span class="site-state-item-name">categories</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">6</span>
                  <span class="site-state-item-name">tags</span>
                </a>
              </div>
            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#Encoder-éƒ¨åˆ†"><span class="nav-number">1.</span> <span class="nav-text">Encoder éƒ¨åˆ†</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Multi-Head-Attentionç»„ä»¶"><span class="nav-number">1.1.</span> <span class="nav-text">Multi-Head Attentionç»„ä»¶</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Feed-Forwardç»„ä»¶"><span class="nav-number">1.2.</span> <span class="nav-text">Feed-Forwardç»„ä»¶</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Residual-Connection-amp-Layer-Normalization"><span class="nav-number">1.3.</span> <span class="nav-text">Residual Connection &amp; Layer Normalization</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#å…³äºPosition-Embedding"><span class="nav-number">1.4.</span> <span class="nav-text">å…³äºPosition Embedding</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Decoderçš„ç»“æ„"><span class="nav-number">2.</span> <span class="nav-text">Decoderçš„ç»“æ„</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Loss-Function"><span class="nav-number">3.</span> <span class="nav-text">Loss Function</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#å¯¹ç°æœ‰å·¥ä½œçš„å¯å‘"><span class="nav-number">4.</span> <span class="nav-text">å¯¹ç°æœ‰å·¥ä½œçš„å¯å‘</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">CSNLP Apprentice</span>

  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Pisces</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  


  

  

</body>
</html>
